{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d0f1a46e1b8bb49f6fe66dfa14ba01e1c4ea6e7377c07a6040c9a42d856a631d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Laboratorio 4 - Pipeline\n",
    "Andrea Cecilia Rivas Castañeda\n",
    "16001120"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import(\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer,\n",
    "    RandomSampleImputer\n",
    ")\n",
    "\n",
    "from feature_engine import transformation as vt\n",
    "\n",
    "from feature_engine.encoding import CountFrequencyEncoder, OneHotEncoder\n",
    "\n",
    "from feature_engine.selection import DropFeatures\n",
    "\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "import my_preprocessors as mypp\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "data.drop([], axis = 1, inplace=True)\n",
    "data.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['Survived'], axis=1),\n",
    "        data['Survived'],\n",
    "        test_size=0.3,\n",
    "        random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRATAMIENTO DE NAs\n",
    "CATEGORICAL_VARS_WITH_NA_MISSING = ['Embarked']\n",
    "\n",
    "NUMERICAL_VARS_WITH_NA = ['Age', 'Fare']\n",
    "\n",
    "RANDOM_NA = ['SibSp', 'Parch','Ticket', 'PassengerId', 'Cabin', 'Name', 'Pclass']\n",
    "\n",
    "# TRANSFORMACIÓN DE VARS CATEGÓRICAS\n",
    "OH_ENCODING_VARS = ['Sex']\n",
    "\n",
    "FREQUENCY_ENCODING_VARS = ['Ticket']\n",
    "\n",
    "CAT_ORDINAL_ENCODING_VARS = ['Embarked']\n",
    "\n",
    "# TRANSFORMACIÓN DE VARS NUMERICAS\n",
    "#Variables para binarización por sesgo fuerte\n",
    "BINARIZE_VARS = ['SibSp', 'Parch']\n",
    "\n",
    "YJ_TRANSFORM = ['Age']\n",
    "LOG_TRANSFORM = ['Fare']\n",
    "\n",
    "# VARIABLES SELECCIONADAS\n",
    "FEATURES = ['Pclass', 'Sex'] \n",
    "\n",
    "DROP_FEATURES = ['SibSp', 'Parch', 'Age', 'Ticket', 'Fare', 'Embarked', 'PassengerId', 'Cabin', 'Name', 'Age_na']# Age_na --> variable para imputación de NA's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivedTitanic_pipeline = Pipeline([\n",
    "    # IMPUTACIONES\n",
    "    # Categoricas - Imputación por fecuencia\n",
    "    ('frequency_imputation', \n",
    "         CategoricalImputer(imputation_method='frequent', variables=CATEGORICAL_VARS_WITH_NA_MISSING)\n",
    "    ),\n",
    "    # Numericas\n",
    "    ('missing_indicator', AddMissingIndicator(variables=NUMERICAL_VARS_WITH_NA)),\n",
    "    \n",
    "    # Imputación de mediana\n",
    "    ('mean_imputation', MeanMedianImputer(\n",
    "        imputation_method='mean', variables=NUMERICAL_VARS_WITH_NA)\n",
    "    ),\n",
    "\n",
    "    ('random_imputation', RandomSampleImputer(variables=RANDOM_NA)),\n",
    "\n",
    "    # TRANSFORMACIONES\n",
    "    # Categoricas\n",
    "    ('ohe_transformation', \n",
    "        OneHotEncoder(variables=OH_ENCODING_VARS, drop_last=True)),\n",
    "    # Numericas\n",
    "    ('yeoJ', vt.YeoJohnsonTransformer(variables=YJ_TRANSFORM)),\n",
    "\n",
    "    ('mlog_plusOne', mypp.PlusOneVariableTransformer(variables=LOG_TRANSFORM)),\n",
    "\n",
    "    ('log', vt.LogTransformer(variables=LOG_TRANSFORM)),\n",
    "\n",
    "    ('binarizer', SklearnTransformerWrapper(\n",
    "        transformer=Binarizer(threshold=0), variables=BINARIZE_VARS)\n",
    "    ),\n",
    "\n",
    "    # Drop de variables\n",
    "    ('drop_features', DropFeatures(features_to_drop=DROP_FEATURES)),\n",
    "\n",
    "    # MODELO\n",
    "    ('Logistic_Reg', LogisticRegression())\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('frequency_imputation',\n",
       "                 CategoricalImputer(imputation_method='frequent',\n",
       "                                    variables=['Embarked'])),\n",
       "                ('missing_indicator',\n",
       "                 AddMissingIndicator(variables=['Age', 'Fare'])),\n",
       "                ('mean_imputation',\n",
       "                 MeanMedianImputer(imputation_method='mean',\n",
       "                                   variables=['Age', 'Fare'])),\n",
       "                ('random_imputation',\n",
       "                 RandomSampleImputer(variables=['SibSp', 'Parch', 'Ticket',\n",
       "                                                'Pa...\n",
       "                 PlusOneVariableTransformer(variables=['Fare'])),\n",
       "                ('log', LogTransformer(variables=['Fare'])),\n",
       "                ('binarizer',\n",
       "                 SklearnTransformerWrapper(transformer=Binarizer(threshold=0),\n",
       "                                           variables=['SibSp', 'Parch'])),\n",
       "                ('drop_features',\n",
       "                 DropFeatures(features_to_drop=['SibSp', 'Parch', 'Age',\n",
       "                                                'Ticket', 'Fare', 'Embarked',\n",
       "                                                'PassengerId', 'Cabin', 'Name',\n",
       "                                                'Age_na'])),\n",
       "                ('Logistic_Reg', LogisticRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "survivedTitanic_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = survivedTitanic_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7985074626865671"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['survivedTitanic_pipeline.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "joblib.dump(survivedTitanic_pipeline, 'survivedTitanic_pipeline.pkl')"
   ]
  }
 ]
}